#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import re
import time
import random
from pathlib import Path
from yt_dlp import YoutubeDL
import logging
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import json

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('download_log.txt', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)

class YouTubeDownloader:
    def __init__(self, cookies_file=None, output_dir='downloads', use_proxy=None):
        """
        åˆå§‹åŒ–ä¸‹è½½å™¨
        :param cookies_file: cookiesæ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºä¸‹è½½éœ€è¦ç™»å½•çš„è§†é¢‘ï¼‰
        :param output_dir: è¾“å‡ºç›®å½•
        :param use_proxy: ä»£ç†è®¾ç½®ï¼Œæ ¼å¼å¦‚ 'socks5://127.0.0.1:1080'
        """
        self.cookies_file = cookies_file
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.use_proxy = use_proxy
        
        # åˆ›å»ºè§†é¢‘å’ŒéŸ³é¢‘å­ç›®å½•
        self.video_dir = self.output_dir / 'videos'
        self.audio_dir = self.output_dir / 'audio'
        self.video_dir.mkdir(exist_ok=True)
        self.audio_dir.mkdir(exist_ok=True)
        
        # åçˆ¬è™«è®¾ç½®
        self.user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:123.0) Gecko/20100101 Firefox/123.0',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2.1 Safari/605.1.15',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36'
        ]
        
        # ä¸‹è½½å»¶è¿Ÿè®¾ç½®ï¼ˆç§’ï¼‰
        self.min_delay = 3
        self.max_delay = 10
        
        # é‡è¯•è®¾ç½®
        self.max_retries = 3
        self.retry_delay = 5
        
    def get_random_headers(self):
        """è·å–éšæœºè¯·æ±‚å¤´"""
        return {
            'User-Agent': random.choice(self.user_agents),
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Cache-Control': 'max-age=0',
        }
    
    def random_delay(self):
        """éšæœºå»¶è¿Ÿï¼Œæ¨¡æ‹Ÿäººç±»è¡Œä¸º"""
        delay = random.uniform(self.min_delay, self.max_delay)
        logging.info(f"ç­‰å¾… {delay:.1f} ç§’...")
        time.sleep(delay)
    
    def sanitize_filename(self, filename):
        """æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤éæ³•å­—ç¬¦"""
        # Windowsæ–‡ä»¶åéæ³•å­—ç¬¦
        illegal_chars = r'[<>:"/\\|?*]'
        filename = re.sub(illegal_chars, '_', filename)
        # ç§»é™¤é¦–å°¾ç©ºæ ¼å’Œç‚¹
        filename = filename.strip('. ')
        # é™åˆ¶æ–‡ä»¶åé•¿åº¦
        if len(filename) > 200:
            filename = filename[:200]
        return filename
    
    def get_base_ydl_opts(self):
        """è·å–åŸºç¡€çš„yt-dlpé€‰é¡¹ï¼ŒåŒ…å«åçˆ¬æªæ–½"""
        opts = {
            'quiet': True,
            'no_warnings': True,
            'ignoreerrors': True,
            'nocheckcertificate': True,
            'no_color': True,
            # åçˆ¬è™«ç›¸å…³è®¾ç½®
            'headers': self.get_random_headers(),
            'socket_timeout': 30,
            'retries': self.max_retries,
            'fragment_retries': self.max_retries,
            'sleep_interval': 1,  # ä¸‹è½½å‰ç­‰å¾…
            'max_sleep_interval': 3,
            'sleep_interval_requests': 1,  # è¯·æ±‚ä¹‹é—´çš„å»¶è¿Ÿ
            # é™é€Ÿè®¾ç½®ï¼ˆé¿å…è¿‡å¿«ä¸‹è½½ï¼‰
            'ratelimit': '5M',  # é™åˆ¶ä¸‹è½½é€Ÿåº¦ä¸º5MB/s
            # å…¶ä»–è®¾ç½®
            'continuedl': True,  # æ–­ç‚¹ç»­ä¼ 
            'noprogress': False,  # æ˜¾ç¤ºè¿›åº¦
        }
        
        # å¦‚æœæœ‰cookiesæ–‡ä»¶ï¼Œæ·»åŠ cookiesé€‰é¡¹
        if self.cookies_file and os.path.exists(self.cookies_file):
            opts['cookiefile'] = self.cookies_file
            logging.info("ä½¿ç”¨cookiesæ–‡ä»¶è¿›è¡Œè®¤è¯")
        
        # å¦‚æœæœ‰ä»£ç†è®¾ç½®
        if self.use_proxy:
            opts['proxy'] = self.use_proxy
            logging.info(f"ä½¿ç”¨ä»£ç†: {self.use_proxy}")
        
        return opts
    
    def download_with_retry(self, download_func, url, video_name, max_retries=None):
        """å¸¦é‡è¯•çš„ä¸‹è½½"""
        if max_retries is None:
            max_retries = self.max_retries
        
        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    logging.info(f"é‡è¯•ç¬¬ {attempt} æ¬¡...")
                    time.sleep(self.retry_delay * attempt)  # é€’å¢å»¶è¿Ÿ
                
                result = download_func(url, video_name)
                if result[0]:  # æˆåŠŸ
                    return result
                
            except Exception as e:
                logging.error(f"ä¸‹è½½å‡ºé”™ (å°è¯• {attempt + 1}/{max_retries}): {str(e)}")
                if attempt < max_retries - 1:
                    continue
                else:
                    raise
        
        return False, None
    
    def download_video(self, url, video_name):
        """ä¸‹è½½è§†é¢‘"""
        try:
            safe_name = self.sanitize_filename(video_name)
            video_path = str(self.video_dir / safe_name)
            
            ydl_opts = self.get_base_ydl_opts()
            ydl_opts.update({
                'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best',
                'outtmpl': f'{video_path}.%(ext)s',
                'merge_output_format': 'mp4',
                # å­—å¹•é€‰é¡¹
                'writesubtitles': True,
                'writeautomaticsub': True,
                'subtitleslangs': ['zh-Hans', 'zh-Hant', 'en'],
                'embedsubtitles': True,
                # åå¤„ç†
                'postprocessors': [{
                    'key': 'FFmpegVideoConvertor',
                    'preferedformat': 'mp4',
                }],
            })
            
            with YoutubeDL(ydl_opts) as ydl:
                logging.info(f"æ­£åœ¨ä¸‹è½½è§†é¢‘: {video_name}")
                info = ydl.extract_info(url, download=True)
                logging.info(f"è§†é¢‘ä¸‹è½½å®Œæˆ: {video_name}")
                return True, info
                
        except Exception as e:
            logging.error(f"ä¸‹è½½è§†é¢‘å¤±è´¥ [{video_name}]: {str(e)}")
            return False, None
    
    def download_audio(self, url, video_name):
        """ä¸‹è½½éŸ³é¢‘"""
        try:
            safe_name = self.sanitize_filename(video_name)
            audio_path = str(self.audio_dir / safe_name)
            
            ydl_opts = self.get_base_ydl_opts()
            ydl_opts.update({
                'format': 'bestaudio/best',
                'outtmpl': f'{audio_path}.%(ext)s',
                'postprocessors': [{
                    'key': 'FFmpegExtractAudio',
                    'preferredcodec': 'mp3',
                    'preferredquality': '320',
                }],
            })
            
            with YoutubeDL(ydl_opts) as ydl:
                logging.info(f"æ­£åœ¨ä¸‹è½½éŸ³é¢‘: {video_name}")
                ydl.download([url])
                logging.info(f"éŸ³é¢‘ä¸‹è½½å®Œæˆ: {video_name}")
                return True
                
        except Exception as e:
            logging.error(f"ä¸‹è½½éŸ³é¢‘å¤±è´¥ [{video_name}]: {str(e)}")
            return False
    
    def download_item(self, video_name, video_url):
        """ä¸‹è½½å•ä¸ªé¡¹ç›®ï¼ˆè§†é¢‘å’ŒéŸ³é¢‘ï¼‰"""
        logging.info(f"\nå¼€å§‹å¤„ç†: {video_name}")
        logging.info(f"é“¾æ¥: {video_url}")
        
        # éšæœºå»¶è¿Ÿï¼Œé¿å…è¿‡å¿«è¯·æ±‚
        self.random_delay()
        
        # ä½¿ç”¨é‡è¯•æœºåˆ¶ä¸‹è½½
        video_success = self.download_with_retry(
            self.download_video, video_url, video_name
        )[0]
        
        # å†æ¬¡å»¶è¿Ÿ
        self.random_delay()
        
        audio_success = self.download_with_retry(
            self.download_audio, video_url, video_name
        )
        
        return video_success and audio_success, video_name, video_url
    
    def process_videos_file(self, videos_file='videos.txt', max_workers=1):
        """å¤„ç†è§†é¢‘åˆ—è¡¨æ–‡ä»¶"""
        if not os.path.exists(videos_file):
            logging.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {videos_file}")
            return
        
        success_count = 0
        fail_count = 0
        failed_items = []
        
        try:
            with open(videos_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # è§£ææœ‰æ•ˆçš„è§†é¢‘é¡¹
            video_items = []
            for i, line in enumerate(lines, 1):
                line = line.strip()
                if not line or line.startswith('#'):
                    continue
                
                parts = line.split(None, 1)
                if len(parts) != 2:
                    logging.warning(f"ç¬¬ {i} è¡Œæ ¼å¼é”™è¯¯ï¼Œè·³è¿‡: {line}")
                    continue
                
                video_items.append(parts)
            
            total_count = len(video_items)
            logging.info(f"æ‰¾åˆ° {total_count} ä¸ªè§†é¢‘å¾…ä¸‹è½½")
            logging.info(f"ä½¿ç”¨ {max_workers} ä¸ªå¹¶å‘ä¸‹è½½")
            
            # é¡ºåºä¸‹è½½ï¼ˆä¸ºäº†æ›´å¥½çš„åçˆ¬ï¼‰
            for i, (video_name, video_url) in enumerate(video_items, 1):
                logging.info(f"\nè¿›åº¦: {i}/{total_count}")
                
                success, name, url = self.download_item(video_name, video_url)
                
                if success:
                    success_count += 1
                    logging.info(f"âœ“ æˆåŠŸä¸‹è½½: {name}")
                else:
                    fail_count += 1
                    failed_items.append(f"{name} {url}")
                    logging.error(f"âœ— ä¸‹è½½å¤±è´¥: {name}")
                
                # æ˜¾ç¤ºå½“å‰ç»Ÿè®¡
                logging.info(f"å½“å‰ç»Ÿè®¡ - æˆåŠŸ: {success_count}, å¤±è´¥: {fail_count}")
        
        except Exception as e:
            logging.error(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        
        # æœ€ç»ˆç»Ÿè®¡
        logging.info(f"\n{'='*50}")
        logging.info(f"ä¸‹è½½å®Œæˆï¼")
        logging.info(f"æˆåŠŸ: {success_count}")
        logging.info(f"å¤±è´¥: {fail_count}")
        
        # ä¿å­˜å¤±è´¥çš„é¡¹ç›®
        if failed_items:
            failed_file = 'failed_videos.txt'
            with open(failed_file, 'w', encoding='utf-8') as f:
                f.write('\n'.join(failed_items))
            logging.info(f"å¤±è´¥çš„è§†é¢‘å·²ä¿å­˜åˆ°: {failed_file}")

def create_cookie_guide():
    """åˆ›å»ºcookiesè·å–æŒ‡å—"""
    guide = """
# ğŸª YouTube Cookies è·å–æŒ‡å—

## æ–¹æ³•ä¸€ï¼šä½¿ç”¨æµè§ˆå™¨æ‰©å±•ï¼ˆæ¨èï¼‰

### Chrome/Edge æµè§ˆå™¨ï¼š
1. å®‰è£…æ‰©å±•ï¼šGet cookies.txt LOCALLY
   - Chrome: https://chrome.google.com/webstore/detail/get-cookiestxt-locally/cclelndahbckbenkjhflpdbgdldlbecc
   - Edge: åœ¨Edgeæ‰©å±•å•†åº—æœç´¢ "Get cookies.txt"

2. ç™»å½•YouTubeå¹¶åŠ å…¥éœ€è¦çš„é¢‘é“ä¼šå‘˜

3. åœ¨YouTubeé¡µé¢ç‚¹å‡»æ‰©å±•å›¾æ ‡ï¼Œé€‰æ‹© "Export" æˆ– "ä¸‹è½½"

4. å°†ä¸‹è½½çš„ cookies.txt æ–‡ä»¶æ”¾åˆ°è„šæœ¬åŒç›®å½•

### Firefox æµè§ˆå™¨ï¼š
1. å®‰è£…æ‰©å±•ï¼šcookies.txt
   - https://addons.mozilla.org/en-US/firefox/addon/cookies-txt/

2. ç™»å½•YouTubeå¹¶åŠ å…¥é¢‘é“ä¼šå‘˜

3. ç‚¹å‡»æ‰©å±•å›¾æ ‡ â†’ Current Site â†’ Export

## æ–¹æ³•äºŒï¼šä½¿ç”¨å¼€å‘è€…å·¥å…·ï¼ˆæŠ€æœ¯ç”¨æˆ·ï¼‰

1. æ‰“å¼€YouTubeå¹¶ç™»å½•è´¦å·
2. æŒ‰F12æ‰“å¼€å¼€å‘è€…å·¥å…·
3. åˆ‡æ¢åˆ° Application/å­˜å‚¨ æ ‡ç­¾
4. å·¦ä¾§æ‰¾åˆ° Cookies â†’ https://www.youtube.com
5. æ‰‹åŠ¨å¤åˆ¶éœ€è¦çš„cookies

ä¸»è¦éœ€è¦çš„cookiesï¼š
- VISITOR_INFO1_LIVE
- PREF
- LOGIN_INFO
- HSID
- SSID
- APISID
- SAPISID
- SID
- SIDCC

## æ–¹æ³•ä¸‰ï¼šä½¿ç”¨yt-dlpç›´æ¥æå–

```bash
# ä»Chromeæµè§ˆå™¨æå–ï¼ˆéœ€è¦å…³é—­æµè§ˆå™¨ï¼‰
yt-dlp --cookies-from-browser chrome --cookies cookies.txt --skip-download [ä»»æ„YouTubeé“¾æ¥]

# ä»Firefoxæå–
yt-dlp --cookies-from-browser firefox --cookies cookies.txt --skip-download [ä»»æ„YouTubeé“¾æ¥]
```

## âš ï¸ æ³¨æ„äº‹é¡¹ï¼š

1. **å®‰å…¨è­¦å‘Š**ï¼šcookiesåŒ…å«ç™»å½•ä¿¡æ¯ï¼Œè¯·å‹¿åˆ†äº«ç»™ä»–äººï¼
2. **æœ‰æ•ˆæœŸ**ï¼šcookieså¯èƒ½è¿‡æœŸï¼Œéœ€è¦å®šæœŸæ›´æ–°
3. **æ ¼å¼è¦æ±‚**ï¼šå¿…é¡»æ˜¯Netscapeæ ¼å¼çš„cookies.txtæ–‡ä»¶
4. **æµ‹è¯•æ–¹æ³•**ï¼šå…ˆç”¨å•ä¸ªä¼šå‘˜è§†é¢‘æµ‹è¯•æ˜¯å¦èƒ½æ­£å¸¸ä¸‹è½½

## éªŒè¯cookiesæ˜¯å¦æœ‰æ•ˆï¼š

å°†cookies.txtæ”¾åˆ°è„šæœ¬ç›®å½•åï¼Œå¯ä»¥ç”¨ä»¥ä¸‹å‘½ä»¤æµ‹è¯•ï¼š
```bash
yt-dlp --cookies cookies.txt -F [ä¼šå‘˜è§†é¢‘é“¾æ¥]
```

å¦‚æœèƒ½çœ‹åˆ°è§†é¢‘æ ¼å¼åˆ—è¡¨ï¼Œè¯´æ˜cookiesæœ‰æ•ˆã€‚

---
åˆ›å»ºæ—¶é—´ï¼š{timestamp}
"""
    return guide.format(timestamp=datetime.now().strftime('%Y-%m-%d %H:%M:%S'))

def main():
    """ä¸»å‡½æ•°"""
    print("YouTubeè§†é¢‘éŸ³é¢‘æ‰¹é‡ä¸‹è½½å·¥å…· v2.0")
    print("=" * 50)
    
    # åˆ›å»ºcookiesè·å–æŒ‡å—
    if not os.path.exists('cookies_guide.txt'):
        with open('cookies_guide.txt', 'w', encoding='utf-8') as f:
            f.write(create_cookie_guide())
        logging.info("å·²åˆ›å»º cookies_guide.txtï¼Œè¯·æŸ¥çœ‹cookiesè·å–æ–¹æ³•")
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    config = {
        'proxy': None,
        'min_delay': 3,
        'max_delay': 10,
        'max_workers': 1,
        'rate_limit': '5M'
    }
    
    if os.path.exists('config.json'):
        try:
            with open('config.json', 'r', encoding='utf-8') as f:
                config.update(json.load(f))
            logging.info("å·²åŠ è½½é…ç½®æ–‡ä»¶ config.json")
        except Exception as e:
            logging.warning(f"é…ç½®æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
    else:
        # åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶
        with open('config.json', 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        logging.info("å·²åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶ config.json")
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦ä½¿ç”¨cookies
    cookies_file = None
    if os.path.exists('cookies.txt'):
        cookies_file = 'cookies.txt'
        logging.info("âœ“ æ£€æµ‹åˆ°cookies.txtæ–‡ä»¶ï¼Œå°†ç”¨äºä¸‹è½½ä¼šå‘˜è§†é¢‘")
    else:
        logging.warning("æœªæ£€æµ‹åˆ°cookies.txtæ–‡ä»¶ï¼Œåªèƒ½ä¸‹è½½å…¬å¼€è§†é¢‘")
        logging.info("å¦‚éœ€ä¸‹è½½ä¼šå‘˜è§†é¢‘ï¼Œè¯·æŸ¥çœ‹ cookies_guide.txt")
    
    # åˆ›å»ºä¸‹è½½å™¨å®ä¾‹
    downloader = YouTubeDownloader(
        cookies_file=cookies_file,
        use_proxy=config.get('proxy')
    )
    
    # åº”ç”¨é…ç½®
    downloader.min_delay = config.get('min_delay', 3)
    downloader.max_delay = config.get('max_delay', 10)
    
    # æ£€æŸ¥videos.txtæ–‡ä»¶
    videos_file = 'videos.txt'
    if not os.path.exists(videos_file):
        logging.error(f"è¯·åˆ›å»º {videos_file} æ–‡ä»¶å¹¶æ·»åŠ è§†é¢‘ä¿¡æ¯")
        logging.info("æ ¼å¼: æ¯è¡Œä¸€ä¸ªè§†é¢‘ï¼Œæ ¼å¼ä¸º 'è§†é¢‘åç§° è§†é¢‘é“¾æ¥'")
        
        # åˆ›å»ºç¤ºä¾‹æ–‡ä»¶
        with open(videos_file, 'w', encoding='utf-8') as f:
            f.write("# YouTubeè§†é¢‘æ‰¹é‡ä¸‹è½½åˆ—è¡¨\n")
            f.write("# æ ¼å¼: è§†é¢‘åç§° è§†é¢‘é“¾æ¥\n")
            f.write("# ä»¥#å¼€å¤´çš„è¡Œå°†è¢«å¿½ç•¥\n")
            f.write("# æç¤ºï¼šè§†é¢‘åç§°ä¸è¦åŒ…å«ç©ºæ ¼ï¼Œå¯ä»¥ç”¨ä¸‹åˆ’çº¿ä»£æ›¿\n\n")
            f.write("# ç¤ºä¾‹ï¼š\n")
            f.write("Pythonæ•™ç¨‹_ç¬¬1é›† https://www.youtube.com/watch?v=dQw4w9WgXcQ\n")
            f.write("Pythonæ•™ç¨‹_ç¬¬2é›† https://www.youtube.com/watch?v=example123\n")
            f.write("# ä¼šå‘˜è§†é¢‘ç¤ºä¾‹ï¼ˆéœ€è¦cookies.txtï¼‰ï¼š\n")
            f.write("# ä¼šå‘˜ä¸“äº«å†…å®¹ https://www.youtube.com/watch?v=member_only\n")
        
        logging.info(f"å·²åˆ›å»ºç¤ºä¾‹æ–‡ä»¶: {videos_file}")
        logging.info("è¯·ç¼–è¾‘è¯¥æ–‡ä»¶åé‡æ–°è¿è¡Œç¨‹åº")
        return
    
    # æ˜¾ç¤ºåçˆ¬é…ç½®
    logging.info(f"\nåçˆ¬è™«é…ç½®:")
    logging.info(f"- è¯·æ±‚å»¶è¿Ÿ: {downloader.min_delay}-{downloader.max_delay}ç§’")
    logging.info(f"- ä¸‹è½½é™é€Ÿ: {config.get('rate_limit', '5M')}")
    logging.info(f"- é‡è¯•æ¬¡æ•°: {downloader.max_retries}")
    logging.info(f"- User-Agentæ± : {len(downloader.user_agents)}ä¸ª")
    
    # è¯¢é—®æ˜¯å¦ç»§ç»­
    print("\næ˜¯å¦å¼€å§‹ä¸‹è½½ï¼Ÿ(y/n): ", end='')
    if input().lower() != 'y':
        logging.info("ç”¨æˆ·å–æ¶ˆä¸‹è½½")
        return
    
    # å¼€å§‹å¤„ç†
    start_time = time.time()
    downloader.process_videos_file(videos_file, max_workers=config.get('max_workers', 1))
    
    # æ˜¾ç¤ºæ€»è€—æ—¶
    elapsed_time = time.time() - start_time
    logging.info(f"\næ€»è€—æ—¶: {elapsed_time/60:.1f} åˆ†é’Ÿ")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        logging.info("\nç”¨æˆ·ä¸­æ–­ä¸‹è½½")
    except Exception as e:
        logging.error(f"ç¨‹åºå¼‚å¸¸: {str(e)}")
        import traceback
        traceback.print_exc()
